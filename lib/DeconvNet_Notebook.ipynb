{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import aux_functions as aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network(x):\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(train_data, [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters = 5,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling layer #2\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training = True)#mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    \n",
    "    return logits, conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cross_entropy(logits, y):\n",
    "    y_pred = tf.nn.softmax(logits, name='y_pred') # the predicted probability for each example.\n",
    "\n",
    "    # Compute the average cross-entropy across all the examples.\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_pred), axis=[1]))\n",
    "    return cross_entropy\n",
    "\n",
    "def compute_accuracy(logits, y):\n",
    "    prediction = tf.argmax(logits, 1, name='pred_class')\n",
    "    true_label = tf.argmax(y, 1, name='true_class')\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, true_label), tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconvolute(layer):\n",
    "    unConv1 = tf.layers.conv2d_transpose( \n",
    "        inputs = layer, \n",
    "        filters = 5, \n",
    "        kernel_size=[5, 5], \n",
    "        padding = \"SAME\")\n",
    "    \n",
    "    return unConv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "MNIST Data Dimensions\n",
      "train_data\n",
      "(50, 784)\n",
      "train_labels\n",
      "(50,)\n",
      "eval\n",
      "(10, 784)\n",
      "eval_labels\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images[:50,] # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels[:50], dtype=np.int32)\n",
    "eval_data = mnist.test.images[:10,] # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels[:10], dtype=np.int32)\n",
    "\n",
    "print(\"\")\n",
    "print(\"MNIST Data Dimensions\")\n",
    "print(\"train_data\")\n",
    "print(train_data.shape)\n",
    "print(\"train_labels\")\n",
    "print(train_labels.shape)\n",
    "print(\"eval\")\n",
    "print(eval_data.shape)\n",
    "print(\"eval_labels\")\n",
    "print(eval_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: accuracy is 0.14000000059604645\n",
      "Step 11: accuracy is 0.8600000143051147\n",
      "Step 21: accuracy is 1.0\n",
      "Step 31: accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Train CNN\n",
    "##\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # We build the model here as before\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name='x')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "    \n",
    "    logits, conv1 = network(x)\n",
    "    loss = compute_cross_entropy(logits = logits, y = y)\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    \n",
    "    onehot_train_labels = tf.one_hot(indices = tf.cast(train_labels, tf.int32), depth = 10)\n",
    "    onehot_eval_labels = tf.one_hot(indices = tf.cast(eval_labels, tf.int32), depth = 10)\n",
    "    \n",
    "    opt = tf.train.AdamOptimizer(0.01)\n",
    "    train_step = opt.minimize(loss)\n",
    "    \n",
    "    #Deconvolute\n",
    "    unConv1 = deconvolute(conv1)\n",
    "    \n",
    "    # Let's put the summaries below\n",
    "    \n",
    "    # create summary for loss and accuracy\n",
    "    tf.summary.scalar('loss', loss) \n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    # create summary for logits\n",
    "    tf.summary.histogram('logits', logits)\n",
    "    \n",
    "    # create summary for input image\n",
    "    tf.summary.image('input', tf.reshape(x, [-1, 28, 28, 1]))\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter('logs/example1', sess.graph)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        lab_train = sess.run(onehot_train_labels)\n",
    "        lab_eval = sess.run(onehot_eval_labels)\n",
    "        \n",
    "        for i in range(31):\n",
    "            _, ac, summary = sess.run((train_step, accuracy, summary_op),\n",
    "                                      feed_dict={x: train_data, y: lab_train})\n",
    "            \n",
    "            # write the summary output to file\n",
    "            summary_writer.add_summary(summary, i)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print('Step {0}: accuracy is {1}'.format(i + 1, ac))\n",
    "    \n",
    "        w = sess.run(unConv1)\n",
    "        #ac = sess.run(accuracy, feed_dict={x: eval_data, y: lab_eval})\n",
    "        #print('Accuracy on test set: {0}'.format(ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 28, 28, 5)\n",
      "[-0.08825822 -0.4269197  -1.35903203 -1.77436566 -2.30783534 -0.71149409\n",
      "  0.50112885  0.27033526 -1.24596632 -1.73115003 -1.07828832 -0.24270964\n",
      "  0.48722535 -0.71931022 -1.78372979 -1.22266042 -0.56201893  0.27340263\n",
      " -0.92770219  0.16941603  1.39464986  1.15155005  0.55716205  0.54184353\n",
      "  0.41318133  0.03183563  0.          0.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw08UFMNPFBTDTxQUw08U1P8BH5KByOpiitEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8001b7b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(w.shape)\n",
    "print(sum(w[1,:,:,1]))\n",
    "\n",
    "plt.imshow(np.array(w[5,:,:,2]), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
