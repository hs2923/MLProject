{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    ###\\n    ### Nested Class: Deconvolutional Neural Network (CNN) for MNIST\\n    ###\\n    class DeconvMnist:\\n        \\n        def __init__( self, outer, session, inDim, outDim, inputImage, inputLabel ):\\n\\n        \\t# data placeholders\\n        \\t#self.inputImage = tf.placeholder(tf.float32, [None, inDim], name=\\'x\\')\\n        \\t#self.inputLabel = tf.placeholder(tf.float32, [None, outDim], name=\\'y\\')\\n\\n        \\t# instantiate outer class in inner class\\n            self.cnn    = outer\\n            self.inDim  = inDim\\n            self.outDim = outDim\\n            self.sess   = session\\n            self.deconv1 = self.deconvLayer1( inputImage, inputLabel )\\n            self.deconv2 = self.deconvLayer2( inputImage, inputLabel )\\n\\n\\n        def deconvLayer1( self, inputImage, inputLabel ):\\n\\n            #\\n            ## Deconvoluting 1st layer\\n            ##\\n            \\n            # get activations for layer 1\\n            activations1 = self.calculateActivations( inputImage, inputLabel, 1 )\\n\\n            # convert from array to tensor\\n            act1_tf = tf.convert_to_tensor( activations1, np.float32 )\\n\\n            # unpool\\n            unPool1 = self.unpool( act1_tf )\\n\\n            # unrelu\\n            unRelu1 = tf.nn.relu( unPool1 )\\n\\n            # deconvolute (filter)\\n            unConv1 = tf.nn.conv2d_transpose(  # check dimensions\\n                #activations1,\\n                unRelu1,\\n                self.cnn.W_c1,\\n                output_shape = [ inputImage.shape[0], 28, 28, 1],\\n                strides = [1, 1, 1, 1],\\n                padding = \"SAME\"  )\\n\\n            return unConv1\\n\\n\\n        def deconvLayer2( self, inputImage, inputLabel ):\\n\\n\\n            ##\\n            ## Deconvoluting 2nd layer\\n            ##\\n\\n            # get activations for layer 2\\n            activations2 = self.calculateActivations(inputImage, inputLabel, 2)\\n\\n            # convert from array to tensor\\n            act1_tf = tf.convert_to_tensor( activations2, np.float32 )\\n\\n            # 1st unpool\\n            unPool1 = self.unpool( act1_tf )\\n\\n            # 1st unrelu\\n            unRelu1 = tf.nn.relu( unPool1 )\\n\\n            # 1st deconvolute (filter)\\n            unConv1 = tf.nn.conv2d_transpose( \\n                #activations1,\\n                unRelu1,\\n                self.cnn.W_c2,\\n                output_shape = [ inputImage.shape[0], 14, 14, 32],\\n                strides = [1, 1, 1, 1],\\n                padding = \"SAME\"  )\\n\\n            # 2nd unpool\\n            unPool2 = self.unpool( unConv1 )\\n\\n            # 2nd relu\\n            unRelu2 = tf.nn.relu( unPool2 )\\n\\n            # 2nd deconvolute (filter)\\n            # 1st deconvolute (filter)\\n            unConv2 = tf.nn.conv2d_transpose( \\n                #activations1,\\n                unRelu2,\\n                self.cnn.W_c1,\\n                output_shape = [ inputImage.shape[0], 28, 28, 1],\\n                strides = [1, 1, 1, 1],\\n                padding = \"SAME\"  )\\n\\n            return unConv2\\n\\n\\n        # calculate activations for layer (1 or 2)\\n        def calculateActivations( self, inputImage, inputLabel, layer ):\\n\\n            if( layer == 1 ):\\n                return self.cnn.pool1.eval(feed_dict={self.cnn.x: np.reshape(inputImage,[-1,self.inDim])})\\n            else:\\n                return self.cnn.pool2.eval(feed_dict={self.cnn.x: np.reshape(inputImage,[-1,self.inDim])})\\n\\n\\n        def getDeconv( self ):\\n            return self.deconv1, self.deconv2\\n\\n        # method to unpool (taken from kvfrans - put link!)\\n        def unpool( self, value ):\\n            \"\"\"N-dimensional version of the unpooling operation from\\n            https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\\n\\n            :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\\n            :return: A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\\n            \"\"\"\\n            #with tf.name_scope(name) as scope:\\n            sh = value.get_shape().as_list()\\n            dim = len(sh[1:-1])\\n            out = (tf.reshape(value, [-1] + sh[-dim:]))\\n            for i in range(dim, 0, -1):\\n                out = tf.concat( [out, out], i)\\n            out_size = [-1] + [s * 2 for s in sh[1:-1]] + [sh[-1]]\\n            out = tf.reshape(out, out_size)#, name=scope)\\n            return out\\n\\n\\n        #def displayFeatures( self, layer ):\\n\\n            #isolated = self.activations1.copy()\\n            #isolated[:,:,:,:1]   = 0\\n            #isolated[:,:,:,1+1:] = 0\\n            #pixelactive = self.unConv1.eval( feed_dict = {self.unConv1PlaceHolder: isolated} )\\n            #return isolated\\n\\n            # if layer == 1:\\n\\n            # \\tisolated = self.activations1.copy()\\n            # \\tisolated[:,:,:,:1]   = 0\\n            # \\tisolated[:,:,:,1+1:] = 0\\n            # \\treturn isolated\\n            # \\t#print(\"isolated shape\")\\n            # \\t#print (np.shape(isolated))\\n            # \\t#totals = np.sum( isolated, axis = (1,2,3) )\\n            # \\t#best   = np.argmin( totals, axis = 0 )\\n            # \\t#print (best)\\n            # \\t#pixelactive = self.unPool1.eval(feed_dict={self.unPool1PlaceHolder: isolated})\\n            # \\t#pixelactive = self.unConv1.eval(feed_dict={self.unConv1PlaceHolder: isolated[5,:,:,1]})\\n\\n            # else:\\n\\n            # \\t# isolated = self.activations2.copy()\\n            # \\t# isolated[:,:,:,:1]   = 0\\n            # \\t# isolated[:,:,:,1+1:] = 0\\n            # \\t# #print (np.shape(isolated))\\n            # \\t# totals = np.sum( isolated, axis = (1,2,3) )\\n            # \\t# best   = np.argmin( totals, axis = 0 )\\n            # \\t# #print (best)\\n            # \\t# #pixelactive = self.unPool2.eval(feed_dict={self.unPool2PlaceHolder: isolated})\\n            # \\t# pixelactive = self.unConv2.eval(feed_dict={self.unConv2PlaceHolder: isolated})\\n\\n\\n            # # saves pixel-representations of features from Conv layer 1\\n            # featuresReLu1 = tf.placeholder(\"float\",[None,32,32,32])\\n            # unReLu = tf.nn.relu(featuresReLu1)\\n            # unBias = unReLu\\n            # unConv = tf.nn.conv2d_transpose(unBias, wConv1, output_shape=[batchsizeFeatures,imagesize,imagesize,colors] , strides=[1,1,1,1], padding=\"SAME\")\\n            # activations1 = relu1.eval(feed_dict={img: inputImage, lbl: inputLabel, keepProb: 1.0})\\n            # print (np.shape(activations1))\\n        \\t# # display features\\n        \\t# for i in xrange(32):\\n        \\t#     isolated = self.activations1.copy()\\n        \\t#     isolated[:,:,:,:i]   = 0\\n        \\t#     isolated[:,:,:,i+1:] = 0\\n        \\t#     #print (np.shape(isolated))\\n        \\t#     totals = np.sum( isolated, axis = (1,2,3) )\\n        \\t#     best   = np.argmin( totals, axis = 0 )\\n        \\t#     #print (best)\\n        \\t#     pixelactive = self.unConv1.eval(feed_dict={self.unPool1PlaceHolder: isolated})\\n        \\t#     # totals = np.sum(pixelactive,axis=(1,2,3))\\n        \\t#     # best = np.argmax(totals,axis=0)\\n        \\t#     # best = 0\\n        \\t#     saveImage(pixelactive[best],\"activ\"+str(i)+\".png\")\\n        \\t#     saveImage(inputImage[best],\"activ\"+str(i)+\"-base.png\")\\n\\n        \\t# return False\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### maybe try to use tf.nn.conv2d?\n",
    "###\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "###\n",
    "### Convolutional Neural Network (CNN) for MNIST\n",
    "###\n",
    "class CnnMnist:\n",
    "    \n",
    "    def __init__( self, session, n_in, n_out, mode ):\n",
    "\n",
    "        # instantiate session\n",
    "        self.session  = session\n",
    "        self.n_in     = n_in  # 28*28\n",
    "        self.n_out    = n_out # 10\n",
    "        self.mode     = mode\n",
    "\n",
    "        # data placeholders\n",
    "        self.x    = tf.placeholder(tf.float32, [None, n_in], name='x')\n",
    "        self.y    = tf.placeholder(tf.float32, [None, n_out], name='y')\n",
    "        self.x_in = tf.reshape(self.x, [-1,self.n_in])\n",
    "        self.W_c1 = tf.get_variable( 'W_c1', shape = [ 5, 5, 1, 32 ] )\n",
    "        self.W_c2 = tf.get_variable( 'W_c2', shape = [ 5, 5, 32, 64 ] )\n",
    "\n",
    "        ##\n",
    "        ## Network Architecture\n",
    "        ##\n",
    "\n",
    "        # Input Layer\n",
    "        self.input_layer = tf.reshape(self.x, [-1, 28, 28, 1])\n",
    "\n",
    "        #\n",
    "        # Convolutional Layer #1\n",
    "        #\n",
    "\n",
    "        # filter\n",
    "        self.conv1 = tf.nn.conv2d(\n",
    "            input = self.input_layer,\n",
    "            filter = self.W_c1,\n",
    "            padding = \"SAME\",\n",
    "            strides = [1,1,1,1] )\n",
    "\n",
    "        # relu\n",
    "        self.relu1 = tf.nn.relu( self.conv1 )\n",
    "\n",
    "        #\n",
    "        # Pooling Layer #1\n",
    "        #\n",
    "        self.pool1 = tf.layers.max_pooling2d(inputs=self.relu1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        #\n",
    "        # Convolutional Layer #2\n",
    "        #\n",
    "\n",
    "        # filter\n",
    "        self.conv2 = tf.nn.conv2d(\n",
    "            input = self.pool1,\n",
    "            filter = self.W_c2,\n",
    "            padding = \"SAME\",\n",
    "            strides = [1,1,1,1] )\n",
    "\n",
    "        # relu\n",
    "        self.relu2 = tf.nn.relu( self.conv2 )\n",
    "\n",
    "        #\n",
    "        # Pooling layer #2\n",
    "        #\n",
    "        self.pool2 = tf.layers.max_pooling2d(inputs=self.conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        #\n",
    "        # Dense Layer\n",
    "        #\n",
    "        pool2_flat = tf.reshape(self.pool2, [-1, 7 * 7 * 64])\n",
    "        dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "        dropout = tf.layers.dropout(\n",
    "            inputs=dense, rate=0.4, training = self.mode )\n",
    "\n",
    "        # Logits Layer\n",
    "        self.logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "        self.q      = tf.argmax(input = self.logits, axis=1)\n",
    "        \n",
    "        # Output Layer\n",
    "        onehot_labels = tf.one_hot( indices = tf.cast(self.y, tf.int32), depth = 10 )\n",
    "        self.loss     = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels = self.y, logits = self.logits )\n",
    "\n",
    "        self.train_step = tf.train.AdamOptimizer(1e-3).minimize(self.loss)\n",
    "\n",
    "    \n",
    "    # method to compute y given x\n",
    "    def compute(self, x):\n",
    "        return self.session.run(self.q, feed_dict={self.x:np.reshape(x,[-1,self.n_in])})\n",
    "    \n",
    "    # method to train network\n",
    "    def train(self, x_batch, y_batch): \n",
    "        # take a training step\n",
    "       _ = self.session.run(self.train_step, feed_dict={self.x: x_batch, self.y: y_batch})\n",
    "\n",
    "    # acessor method for output after pooling layers\n",
    "    def getPools(self):\n",
    "        return ( self.pool1, self.pool2 )\n",
    "\n",
    "    # acessor method for output after convolutional layers\n",
    "    def getConvs(self):\n",
    "        return ( self.conv1, self.conv2 )\n",
    "\n",
    "    # acessor method for loss\n",
    "    def getLoss(self):\n",
    "        return self.loss\n",
    "\n",
    "    # saver method to save trained cnn in disk \n",
    "    def netSaver(self, savePath):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(self.session, savePath)\n",
    "        print(\"Model saved in file: %s\" % savePath)\n",
    "\n",
    "    # loader method to restore weights of a pretrained cnn\n",
    "    def netLoader(self, loadPath):\n",
    "        loader = tf.train.Saver({\"W_c1\":self.W_c1, \"W_c2\":self.W_c2})\n",
    "        restoredModel= loader.restore(self.session, loadPath)\n",
    "        print(\"Model restored from %s\" % loadPath)\n",
    "\n",
    "\n",
    "    # method to initialize filter weights\n",
    "    def initWeight(shape):\n",
    "        weights = tf.truncated_normal(shape,stddev=0.1)\n",
    "        return tf.Variable(weights)\n",
    "\n",
    "    # method to instantiate deconvolutional neural net\n",
    "    def createDeconvNet(self, inputImage, inputLabel):\n",
    "        return CnnMnist.DeconvMnist( self, self.session, self.n_in, self.n_out, inputImage, inputLabel )\n",
    "\n",
    "'''\n",
    "    ###\n",
    "    ### Nested Class: Deconvolutional Neural Network (CNN) for MNIST\n",
    "    ###\n",
    "    class DeconvMnist:\n",
    "        \n",
    "        def __init__( self, outer, session, inDim, outDim, inputImage, inputLabel ):\n",
    "\n",
    "        \t# data placeholders\n",
    "        \t#self.inputImage = tf.placeholder(tf.float32, [None, inDim], name='x')\n",
    "        \t#self.inputLabel = tf.placeholder(tf.float32, [None, outDim], name='y')\n",
    "\n",
    "        \t# instantiate outer class in inner class\n",
    "            self.cnn    = outer\n",
    "            self.inDim  = inDim\n",
    "            self.outDim = outDim\n",
    "            self.sess   = session\n",
    "            self.deconv1 = self.deconvLayer1( inputImage, inputLabel )\n",
    "            self.deconv2 = self.deconvLayer2( inputImage, inputLabel )\n",
    "\n",
    "\n",
    "        def deconvLayer1( self, inputImage, inputLabel ):\n",
    "\n",
    "            #\n",
    "            ## Deconvoluting 1st layer\n",
    "            ##\n",
    "            \n",
    "            # get activations for layer 1\n",
    "            activations1 = self.calculateActivations( inputImage, inputLabel, 1 )\n",
    "\n",
    "            # convert from array to tensor\n",
    "            act1_tf = tf.convert_to_tensor( activations1, np.float32 )\n",
    "\n",
    "            # unpool\n",
    "            unPool1 = self.unpool( act1_tf )\n",
    "\n",
    "            # unrelu\n",
    "            unRelu1 = tf.nn.relu( unPool1 )\n",
    "\n",
    "            # deconvolute (filter)\n",
    "            unConv1 = tf.nn.conv2d_transpose(  # check dimensions\n",
    "                #activations1,\n",
    "                unRelu1,\n",
    "                self.cnn.W_c1,\n",
    "                output_shape = [ inputImage.shape[0], 28, 28, 1],\n",
    "                strides = [1, 1, 1, 1],\n",
    "                padding = \"SAME\"  )\n",
    "\n",
    "            return unConv1\n",
    "\n",
    "\n",
    "        def deconvLayer2( self, inputImage, inputLabel ):\n",
    "\n",
    "\n",
    "            ##\n",
    "            ## Deconvoluting 2nd layer\n",
    "            ##\n",
    "\n",
    "            # get activations for layer 2\n",
    "            activations2 = self.calculateActivations(inputImage, inputLabel, 2)\n",
    "\n",
    "            # convert from array to tensor\n",
    "            act1_tf = tf.convert_to_tensor( activations2, np.float32 )\n",
    "\n",
    "            # 1st unpool\n",
    "            unPool1 = self.unpool( act1_tf )\n",
    "\n",
    "            # 1st unrelu\n",
    "            unRelu1 = tf.nn.relu( unPool1 )\n",
    "\n",
    "            # 1st deconvolute (filter)\n",
    "            unConv1 = tf.nn.conv2d_transpose( \n",
    "                #activations1,\n",
    "                unRelu1,\n",
    "                self.cnn.W_c2,\n",
    "                output_shape = [ inputImage.shape[0], 14, 14, 32],\n",
    "                strides = [1, 1, 1, 1],\n",
    "                padding = \"SAME\"  )\n",
    "\n",
    "            # 2nd unpool\n",
    "            unPool2 = self.unpool( unConv1 )\n",
    "\n",
    "            # 2nd relu\n",
    "            unRelu2 = tf.nn.relu( unPool2 )\n",
    "\n",
    "            # 2nd deconvolute (filter)\n",
    "            # 1st deconvolute (filter)\n",
    "            unConv2 = tf.nn.conv2d_transpose( \n",
    "                #activations1,\n",
    "                unRelu2,\n",
    "                self.cnn.W_c1,\n",
    "                output_shape = [ inputImage.shape[0], 28, 28, 1],\n",
    "                strides = [1, 1, 1, 1],\n",
    "                padding = \"SAME\"  )\n",
    "\n",
    "            return unConv2\n",
    "\n",
    "\n",
    "        # calculate activations for layer (1 or 2)\n",
    "        def calculateActivations( self, inputImage, inputLabel, layer ):\n",
    "\n",
    "            if( layer == 1 ):\n",
    "                return self.cnn.pool1.eval(feed_dict={self.cnn.x: np.reshape(inputImage,[-1,self.inDim])})\n",
    "            else:\n",
    "                return self.cnn.pool2.eval(feed_dict={self.cnn.x: np.reshape(inputImage,[-1,self.inDim])})\n",
    "\n",
    "\n",
    "        def getDeconv( self ):\n",
    "            return self.deconv1, self.deconv2\n",
    "\n",
    "        # method to unpool (taken from kvfrans - put link!)\n",
    "        def unpool( self, value ):\n",
    "            \"\"\"N-dimensional version of the unpooling operation from\n",
    "            https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n",
    "\n",
    "            :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\n",
    "            :return: A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\n",
    "            \"\"\"\n",
    "            #with tf.name_scope(name) as scope:\n",
    "            sh = value.get_shape().as_list()\n",
    "            dim = len(sh[1:-1])\n",
    "            out = (tf.reshape(value, [-1] + sh[-dim:]))\n",
    "            for i in range(dim, 0, -1):\n",
    "                out = tf.concat( [out, out], i)\n",
    "            out_size = [-1] + [s * 2 for s in sh[1:-1]] + [sh[-1]]\n",
    "            out = tf.reshape(out, out_size)#, name=scope)\n",
    "            return out\n",
    "\n",
    "\n",
    "        #def displayFeatures( self, layer ):\n",
    "\n",
    "            #isolated = self.activations1.copy()\n",
    "            #isolated[:,:,:,:1]   = 0\n",
    "            #isolated[:,:,:,1+1:] = 0\n",
    "            #pixelactive = self.unConv1.eval( feed_dict = {self.unConv1PlaceHolder: isolated} )\n",
    "            #return isolated\n",
    "\n",
    "            # if layer == 1:\n",
    "\n",
    "            # \tisolated = self.activations1.copy()\n",
    "            # \tisolated[:,:,:,:1]   = 0\n",
    "            # \tisolated[:,:,:,1+1:] = 0\n",
    "            # \treturn isolated\n",
    "            # \t#print(\"isolated shape\")\n",
    "            # \t#print (np.shape(isolated))\n",
    "            # \t#totals = np.sum( isolated, axis = (1,2,3) )\n",
    "            # \t#best   = np.argmin( totals, axis = 0 )\n",
    "            # \t#print (best)\n",
    "            # \t#pixelactive = self.unPool1.eval(feed_dict={self.unPool1PlaceHolder: isolated})\n",
    "            # \t#pixelactive = self.unConv1.eval(feed_dict={self.unConv1PlaceHolder: isolated[5,:,:,1]})\n",
    "\n",
    "            # else:\n",
    "\n",
    "            # \t# isolated = self.activations2.copy()\n",
    "            # \t# isolated[:,:,:,:1]   = 0\n",
    "            # \t# isolated[:,:,:,1+1:] = 0\n",
    "            # \t# #print (np.shape(isolated))\n",
    "            # \t# totals = np.sum( isolated, axis = (1,2,3) )\n",
    "            # \t# best   = np.argmin( totals, axis = 0 )\n",
    "            # \t# #print (best)\n",
    "            # \t# #pixelactive = self.unPool2.eval(feed_dict={self.unPool2PlaceHolder: isolated})\n",
    "            # \t# pixelactive = self.unConv2.eval(feed_dict={self.unConv2PlaceHolder: isolated})\n",
    "\n",
    "\n",
    "            # # saves pixel-representations of features from Conv layer 1\n",
    "            # featuresReLu1 = tf.placeholder(\"float\",[None,32,32,32])\n",
    "            # unReLu = tf.nn.relu(featuresReLu1)\n",
    "            # unBias = unReLu\n",
    "            # unConv = tf.nn.conv2d_transpose(unBias, wConv1, output_shape=[batchsizeFeatures,imagesize,imagesize,colors] , strides=[1,1,1,1], padding=\"SAME\")\n",
    "            # activations1 = relu1.eval(feed_dict={img: inputImage, lbl: inputLabel, keepProb: 1.0})\n",
    "            # print (np.shape(activations1))\n",
    "        \t# # display features\n",
    "        \t# for i in xrange(32):\n",
    "        \t#     isolated = self.activations1.copy()\n",
    "        \t#     isolated[:,:,:,:i]   = 0\n",
    "        \t#     isolated[:,:,:,i+1:] = 0\n",
    "        \t#     #print (np.shape(isolated))\n",
    "        \t#     totals = np.sum( isolated, axis = (1,2,3) )\n",
    "        \t#     best   = np.argmin( totals, axis = 0 )\n",
    "        \t#     #print (best)\n",
    "        \t#     pixelactive = self.unConv1.eval(feed_dict={self.unPool1PlaceHolder: isolated})\n",
    "        \t#     # totals = np.sum(pixelactive,axis=(1,2,3))\n",
    "        \t#     # best = np.argmax(totals,axis=0)\n",
    "        \t#     # best = 0\n",
    "        \t#     saveImage(pixelactive[best],\"activ\"+str(i)+\".png\")\n",
    "        \t#     saveImage(inputImage[best],\"activ\"+str(i)+\"-base.png\")\n",
    "\n",
    "        \t# return False\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "error rate BEFORE training is 0.924\n",
      "error rate during training is 0.376\n",
      "error rate during training is 0.268\n",
      "error rate during training is 0.221\n",
      "error rate during training is 0.215\n",
      "error rate during training is 0.182\n",
      "Model saved in file: ./tmp/cnnMnist\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda64\\envs\\AdvML\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import script with auxiliar functions\n",
    "import ConvDeconvClasses_NEW as nets\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "\n",
    "  ############################################\n",
    "  ## Load MNIST data\n",
    "  ############################################\n",
    "\n",
    "  # Load training and eval data\n",
    "  mnist        = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  train_data   = mnist.train.images[0:1000] # Returns np.array - reading only 1000 images\n",
    "  train_labels = np.asarray(mnist.train.labels[0:1000], dtype=np.int32) # - reading only 1000 images\n",
    "  eval_data    = mnist.test.images[0:200] # Returns np.array - reading only 200 images\n",
    "  eval_labels  = np.asarray(mnist.test.labels[0:200], dtype=np.int32) # - reading only 200 images\n",
    "\n",
    "\n",
    "  ############################################\n",
    "  ## Run session\n",
    "  ############################################\n",
    "  with tf.Graph().as_default():\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "\n",
    "\n",
    "        # instatiate Network\n",
    "        net = nets.CnnMnist(sess, 28*28, 10, True ) # True stands for training\n",
    "\n",
    "        #DeconvNet = net.createDeconvNet()\n",
    "\n",
    "        #act11  = DeconvNet.calculateActivations(train_data, train_labels, 1)\n",
    "        #plt.imshow(np.array(act11[5,:,:,2]), cmap='gray')\n",
    "        #plt.show()\n",
    "\n",
    "        # usual tf initialization\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # make labels one-hot encoded\n",
    "        onehot_labels_train = tf.one_hot( indices = tf.cast(train_labels, tf.int32), depth =  10 )\n",
    "\n",
    "        # print error rate before training\n",
    "        print('error rate BEFORE training is {}'.format((np.sum(net.compute(train_data)!=train_labels) / train_labels.size)))\n",
    "\n",
    "        # train network\n",
    "        net.train( train_data, onehot_labels_train.eval() )\n",
    "\n",
    "        # now train...\n",
    "        for i in range(5):\n",
    "            net.train(train_data,onehot_labels_train.eval())\n",
    "            print('error rate during training is {}'.format(( np.sum(net.compute(train_data)!=train_labels) / train_labels.size)))\n",
    "        \n",
    "        # save the trained network \n",
    "        net.netSaver(\"./tmp/cnnMnist\")\n",
    "\n",
    "        '''\n",
    "        ##\n",
    "        ## Deconvolution Part - until here it runs OK\n",
    "        ##\n",
    "        \n",
    "        # instantiate deconv net\n",
    "        DeconvNet = net.createDeconvNet( train_data, train_labels )\n",
    "\n",
    "        print( \"\\nDimension of input data\")\n",
    "        print( train_data.shape)\n",
    "\n",
    "        print( \"\\nNumber of Images\")\n",
    "        print( train_data.shape[0])\n",
    "\n",
    "        dec1, dec2  = DeconvNet.getDeconv()\n",
    "\n",
    "        print( \"\\nDimension of Deconvoluted images - Layer 1\")\n",
    "        print( dec1.shape )\n",
    "        print( dec1 )\n",
    "\n",
    "        print( \"\\nDimension of Deconvoluted images - Layer 2\")\n",
    "        print( dec2.shape )\n",
    "        print( dec2 )\n",
    "\n",
    "        a1 = dec2.eval()\n",
    "        plt.imshow(np.array(a1[1,:,:,0]), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # plt.imshow(np.array(train_data[1,:,:,0]), cmap='gray')\n",
    "        # plt.show()\n",
    "\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
